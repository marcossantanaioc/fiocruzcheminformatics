{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Normalizer, normalize, RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from functools import partial\n",
    "from sklearn.model_selection import cross_val_score, KFold, train_test_split\n",
    "from sklearn.metrics import make_scorer,r2_score, mean_absolute_error, mean_squared_error\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from pathlib import Path\n",
    "from joblib import load, dump\n",
    "import optuna\n",
    "\n",
    "from rdkit.Chem import MolFromSmiles, MolToSmiles\n",
    "from rdkit.Chem.AllChem import GetMorganFingerprintAsBitVect\n",
    "\n",
    "from descriptastorus.descriptors import rdNormalizedDescriptors, AtomPairCounts\n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "from statsmodels.graphics.gofplots import qqplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize': (12, 10)})\n",
    "sns.set_style('whitegrid')\n",
    "sns.set_context('paper',font_scale=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DIR = Path('../models/LOGS/random_split/PropertyFP_reduced/aqsoldb')\n",
    "SAVE_DIR.mkdir(exist_ok=True,parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Name</th>\n",
       "      <th>InChI</th>\n",
       "      <th>InChIKey</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>SD</th>\n",
       "      <th>Ocurrences</th>\n",
       "      <th>Group</th>\n",
       "      <th>MolWt</th>\n",
       "      <th>...</th>\n",
       "      <th>NumValenceElectrons</th>\n",
       "      <th>NumAromaticRings</th>\n",
       "      <th>NumSaturatedRings</th>\n",
       "      <th>NumAliphaticRings</th>\n",
       "      <th>RingCount</th>\n",
       "      <th>TPSA</th>\n",
       "      <th>LabuteASA</th>\n",
       "      <th>BalabanJ</th>\n",
       "      <th>BertzCT</th>\n",
       "      <th>processed_smiles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-3</td>\n",
       "      <td>N,N,N-trimethyloctadecan-1-aminium bromide</td>\n",
       "      <td>InChI=1S/C21H46N.BrH/c1-5-6-7-8-9-10-11-12-13-...</td>\n",
       "      <td>SZEMGTQCPRNXEG-UHFFFAOYSA-M</td>\n",
       "      <td>[Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>\n",
       "      <td>-3.616127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>G1</td>\n",
       "      <td>392.510</td>\n",
       "      <td>...</td>\n",
       "      <td>142.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>158.520601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>210.377334</td>\n",
       "      <td>CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A-4</td>\n",
       "      <td>Benzo[cd]indol-2(1H)-one</td>\n",
       "      <td>InChI=1S/C11H7NO/c13-11-8-5-1-3-7-4-2-6-9(12-1...</td>\n",
       "      <td>GPYLCFQEKPUWLD-UHFFFAOYSA-N</td>\n",
       "      <td>O=C1Nc2cccc3cccc1c23</td>\n",
       "      <td>-3.254767</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>G1</td>\n",
       "      <td>169.183</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>29.10</td>\n",
       "      <td>75.183563</td>\n",
       "      <td>2.582996</td>\n",
       "      <td>511.229248</td>\n",
       "      <td>O=C1Nc2cccc3cccc1c23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A-5</td>\n",
       "      <td>4-chlorobenzaldehyde</td>\n",
       "      <td>InChI=1S/C7H5ClO/c8-7-3-1-6(5-9)2-4-7/h1-5H</td>\n",
       "      <td>AVPYQKSLYISFPO-UHFFFAOYSA-N</td>\n",
       "      <td>Clc1ccc(C=O)cc1</td>\n",
       "      <td>-2.177078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>G1</td>\n",
       "      <td>140.569</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.07</td>\n",
       "      <td>58.261134</td>\n",
       "      <td>3.009782</td>\n",
       "      <td>202.661065</td>\n",
       "      <td>O=Cc1ccc(Cl)cc1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A-9</td>\n",
       "      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n",
       "      <td>InChI=1S/C25H30N2O4/c1-5-20(26(10-22-14-28-22)...</td>\n",
       "      <td>FAUAZXVRLVIARB-UHFFFAOYSA-N</td>\n",
       "      <td>C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...</td>\n",
       "      <td>-4.662065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>G1</td>\n",
       "      <td>422.525</td>\n",
       "      <td>...</td>\n",
       "      <td>164.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>56.60</td>\n",
       "      <td>183.183268</td>\n",
       "      <td>1.084427</td>\n",
       "      <td>769.899934</td>\n",
       "      <td>c1cc(N(CC2CO2)CC2CO2)ccc1Cc1ccc(N(CC2CO2)CC2CO...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A-10</td>\n",
       "      <td>vinyltoluene</td>\n",
       "      <td>InChI=1S/C9H10/c1-3-9-6-4-5-8(2)7-9/h3-7H,1H2,2H3</td>\n",
       "      <td>JZHGRUMIRATHIU-UHFFFAOYSA-N</td>\n",
       "      <td>Cc1cccc(C=C)c1</td>\n",
       "      <td>-3.123150</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>G1</td>\n",
       "      <td>118.179</td>\n",
       "      <td>...</td>\n",
       "      <td>46.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>55.836626</td>\n",
       "      <td>3.070761</td>\n",
       "      <td>211.033225</td>\n",
       "      <td>C=Cc1cccc(C)c1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID                                               Name  \\\n",
       "0   A-3         N,N,N-trimethyloctadecan-1-aminium bromide   \n",
       "1   A-4                           Benzo[cd]indol-2(1H)-one   \n",
       "2   A-5                               4-chlorobenzaldehyde   \n",
       "3   A-9  4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n",
       "4  A-10                                       vinyltoluene   \n",
       "\n",
       "                                               InChI  \\\n",
       "0  InChI=1S/C21H46N.BrH/c1-5-6-7-8-9-10-11-12-13-...   \n",
       "1  InChI=1S/C11H7NO/c13-11-8-5-1-3-7-4-2-6-9(12-1...   \n",
       "2        InChI=1S/C7H5ClO/c8-7-3-1-6(5-9)2-4-7/h1-5H   \n",
       "3  InChI=1S/C25H30N2O4/c1-5-20(26(10-22-14-28-22)...   \n",
       "4  InChI=1S/C9H10/c1-3-9-6-4-5-8(2)7-9/h3-7H,1H2,2H3   \n",
       "\n",
       "                      InChIKey  \\\n",
       "0  SZEMGTQCPRNXEG-UHFFFAOYSA-M   \n",
       "1  GPYLCFQEKPUWLD-UHFFFAOYSA-N   \n",
       "2  AVPYQKSLYISFPO-UHFFFAOYSA-N   \n",
       "3  FAUAZXVRLVIARB-UHFFFAOYSA-N   \n",
       "4  JZHGRUMIRATHIU-UHFFFAOYSA-N   \n",
       "\n",
       "                                              SMILES  Solubility   SD  \\\n",
       "0                [Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C   -3.616127  0.0   \n",
       "1                               O=C1Nc2cccc3cccc1c23   -3.254767  0.0   \n",
       "2                                    Clc1ccc(C=O)cc1   -2.177078  0.0   \n",
       "3  C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...   -4.662065  0.0   \n",
       "4                                     Cc1cccc(C=C)c1   -3.123150  0.0   \n",
       "\n",
       "   Ocurrences Group    MolWt  ...  NumValenceElectrons  NumAromaticRings  \\\n",
       "0           1    G1  392.510  ...                142.0               0.0   \n",
       "1           1    G1  169.183  ...                 62.0               2.0   \n",
       "2           1    G1  140.569  ...                 46.0               1.0   \n",
       "3           1    G1  422.525  ...                164.0               2.0   \n",
       "4           1    G1  118.179  ...                 46.0               1.0   \n",
       "\n",
       "   NumSaturatedRings  NumAliphaticRings  RingCount   TPSA   LabuteASA  \\\n",
       "0                0.0                0.0        0.0   0.00  158.520601   \n",
       "1                0.0                1.0        3.0  29.10   75.183563   \n",
       "2                0.0                0.0        1.0  17.07   58.261134   \n",
       "3                4.0                4.0        6.0  56.60  183.183268   \n",
       "4                0.0                0.0        1.0   0.00   55.836626   \n",
       "\n",
       "   BalabanJ     BertzCT                                   processed_smiles  \n",
       "0  0.000000  210.377334                      CCCCCCCCCCCCCCCCCC[N+](C)(C)C  \n",
       "1  2.582996  511.229248                               O=C1Nc2cccc3cccc1c23  \n",
       "2  3.009782  202.661065                                    O=Cc1ccc(Cl)cc1  \n",
       "3  1.084427  769.899934  c1cc(N(CC2CO2)CC2CO2)ccc1Cc1ccc(N(CC2CO2)CC2CO...  \n",
       "4  3.070761  211.033225                                     C=Cc1cccc(C)c1  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/AqSOLDB/curated-solubility-dataset_processed.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Featurize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getfp(mol, nBits=1024,radius=2):\n",
    "    mol = MolFromSmiles(mol)\n",
    "\n",
    "    fp = GetMorganFingerprintAsBitVect(mol,radius=radius,nBits=nBits)\n",
    "    return np.array(fp).reshape(-1,nBits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = rdNormalizedDescriptors.RDKit2DNormalized()\n",
    "generator_atompair = AtomPairCounts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x[0] for x in generator.columns]\n",
    "len(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [x[0] for x in generator.columns]\n",
    "len(features)\n",
    "features_df = pd.DataFrame(np.concatenate(generator.processSmiles(data.processed_smiles.tolist())[1]).reshape(data.shape[0],-1)[:, 1:],columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = pd.DataFrame(features_df,columns=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.columns[features_df.isnull().any().values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do have missing values. Let's see who is causing this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df.loc[features_df['MaxAbsPartialCharge'].isnull(),'value_is_NaN'] = 'Yes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df[~features_df['value_is_NaN'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx = features_df[~features_df['value_is_NaN'].isnull()].index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just one molecule for which charges could not be calculated. Let's take a look into its structure and SMILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[wrong_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MolFromSmiles('[C-]#[O+]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the MolWT x LogS plot, it doesnt seem to be an outlier. I think we just remove it, just in case..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(wrong_idx,inplace=True)\n",
    "features_df.drop(wrong_idx,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slic = data[['ID', 'Name', 'InChI', 'InChIKey', 'SMILES', 'processed_smiles', 'Solubility', 'SD',\n",
    "       'Ocurrences', 'Group']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat = pd.concat([slic, features_df],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat.drop('value_is_NaN',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat.to_csv('../data/AqSOLDB/curated-solubility-dataset_processed_rdki2dnormalized.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat.columns[data_feat.isnull().any().values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove the outlier A-2512. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat = data_feat[data_feat['ID']!=\"A-2512\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "ax=sns.scatterplot(*embedding.T,s=90, hue=hu, palette='seismic')\n",
    "\n",
    "\n",
    "norm = plt.Normalize(data_feat['Solubility'].min(), data_feat['Solubility'].max())\n",
    "sm = plt.cm.ScalarMappable(cmap=\"seismic\", norm=norm)\n",
    "sm.set_array([])\n",
    "plt.legend('LogS')\n",
    "# Remove the legend and add a colorbar\n",
    "ax.get_legend().remove()\n",
    "ax.set_xlabel('UMAP1')\n",
    "ax.set_ylabel('UMAP2')\n",
    "ax.figure.colorbar(sm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we wil be using A LOT of physicochemical descriptors (e.g. molecular weight, TPSA, chi values etc), let's check which ones we could ignore before training different models. This might help us train faster and include only powerful predictions in our data. In addition, it might help us avoid overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "esol_x = data_feat[features].values\n",
    "esol_y = data_feat['Solubility'].values\n",
    "\n",
    "print(esol_x.shape, esol_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mutal information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Mutual information](https://thuijskens.github.io/2017/10/07/feature-selection/) is a measure between two (possibly multi-dimensional) random variables $X$ and $Y$, that quantifies the amount of information obtained about one random variable, through the other random variable. The mutual information is given by:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "I(X; Y) = \\int_X \\int_Y p(x, y) \\log \\frac{p(x, y)}{p(x) p(y)} dx dy\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If the joint distribution $p(x,y)$ of variables $X$ and $Y$ equals the individual probabilities $p(x)$ and $p(y)$, the variables are considered independent the integral is 0. Therefore, our goal is to find variables that are somehow correlated with the dependent variable logS. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importances = mutual_info_regression(esol_x, esol_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importances = pd.DataFrame(importances,index=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importances.sort_values(0,ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_relevant_mi = df_importances.sort_values(0,ascending=False).head(20).index.tolist()\n",
    "most_relevant_mi[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first, it seems that the top-20 most correlated features with logS makes sense. For instance, the LogP is definitely important to define solubility, with more lipophilic molecules being less water-soluble. \n",
    "After logP, 0 and 1-order chi descriptors seems to be the most correlated. This chi descriptors essentialy encode the topology of a molecule, including its valence and sigma electrons, lone pairs the the degree of branching. In a similar way, the molecular refractivity (MolMR) encodes the steric bulk of a molecule because it is calculated from the molecular volume. \n",
    "In summary, the top 20 most correlated descriptors are properties that impact the solubility of molecules in some way. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importances.sort_values(0,ascending=False).tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the bottom 20 features we can see that the are mostly related to fractions of specific chemical groups, which does tells us something about the structure but are not determinant for solubility per se. For instance, a molecule with nitro groups might not be soluble even considering the high polarility of this group. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, that already give us some ideas about which descriptors should be in the logS estimator. In a future next step, we'll further filter this collection of features. For now,  let's select any feature with MI > 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = df_importances[df_importances[0]>0].index.tolist()#np.array(features)[selectkbest.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_feat[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now for something different: Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try all feature selection methods from scikit-learn but one method that I prefer to use is random forest (RF). Random forest is a learning algorithm that uses the average response of an ensemble of decision trees to make a prediction. Not only data, but the algorithm reduces overfitting but using different data samples and features at each tree, which essentialy decorrelates each predictor. Since the underlying model uses splits based on different input features, we can ask the model which features it considered the most important to make a split with the ```feature_importance_``` variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to validate the predictions, we'll use out-of-the-bag samples as a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_model = RandomForestRegressor(2000,n_jobs=-1, oob_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_model.fit(data_feat[selected_features].values, esol_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_preds = feat_model.oob_prediction_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oob_preds.shape, esol_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_feat_importance(model, feats_names):\n",
    "    return pd.DataFrame({'cols':feats_names, 'imp':model.feature_importances_}).sort_values('imp',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi = rf_feat_importance(feat_model, selected_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_importances.sort_values(0,ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fi.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fi(fi):\n",
    "    return fi.plot('cols','imp','barh',figsize=(16,12),legend=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_fi(fi[:25])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the most relevant descriptors make sense. For instance, the top predictor of solubility is the logP (lipophilicity of the molecule). Other importante descriptors include molar refractivity, partial charge, some topological descriptors (e.g. Chi, BertzCT, SMR_VSA10), the total polar surface area and the number of heteroatoms. However, logP **DOMINATES** all other features by a large margin. This is consistent with the original [ESOL publication](https://doi.org/10.1021/ci034243x)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try selecting only features if their importance is **> 5% (0.005)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_relevant_features = fi[fi['imp']>=0.005]\n",
    "most_relevant_features_idx = most_relevant_features.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_relevant_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recently I learned in the FASTAI course how to cluster the features in order to further the features. If two feature are highly correlated, we can eliminate one of them or maybe merge them into a unique feature. Let's try plotting a dendrogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy.cluster import hierarchy as hc\n",
    "\n",
    "def cluster_columns(df, figsize=(12,16), font_size=18):\n",
    "    corr = np.round(scipy.stats.spearmanr(df).correlation, 4)\n",
    "    corr_condensed = hc.distance.squareform(1-corr)\n",
    "    z = hc.linkage(corr_condensed, method='average')\n",
    "    fig = plt.figure(figsize=figsize)\n",
    "    hc.dendrogram(z, labels=df.columns, orientation='left', leaf_font_size=font_size)\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_imps = pd.DataFrame(data[most_relevant_features.cols.values.tolist()],columns=most_relevant_features.cols.values.tolist()).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_imps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_columns(xs_imps)\n",
    "#plt.savefig(SAVE_DIR/'feature_importance_clustering.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,20))\n",
    "sns.set_context(font_scale=1.5)\n",
    "ax=sns.heatmap(xs_imps.corr(), cmap='magma', annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chi, BertzCT and MolMR are the most correlated descriptors. In addition, MinPartialCharge and MaxAbsPartialCharge charge are the most correlated features. \n",
    "Surprisingly, the [quantitative estimation of drug-likeness - qed](https://www.rdkit.org/docs/source/rdkit.Chem.QED.html) shows up among the most relevant features! The qed value basically incorporates many physicochemical properties, such as logP, molecular weight, TPSA, HBD and HBA in order to estimate the druglikeness of a molecule. But wait a second... We already have some of these properties among out selected features! No wonder qed is in the same cluster as MolLogP, chi descriptors, max partial charges and molar refractivity. It actually embed these features into a single value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pruning the tree a little bit more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time we'll use recursive feature elimination in order to select the best set of features based on RF feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruner = RandomForestRegressor(2000,n_jobs=-1)\n",
    "selector = RFECV(pruner, step=1, cv=5, min_features_to_select=5)\n",
    "selector.fit(data[most_relevant_features.cols],esol_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.grid_scores_.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector.n_features_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_list = most_relevant_features.cols.values[selector.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_relevant_features.cols.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_columns(data[pruned_list])\n",
    "#plt.savefig(SAVE_DIR/'feature_importance_clustering.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chi4v and FpDensityMorgan1 features were removed. Well, there are many lower-tier chi descriptors already present and the contribution of density of circular fingerprints doesnt really give any new information compared to topological descriptors, including chi. By the dendrogram, it seems we could also remove Chi1V or MolMR. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oob(df):\n",
    "    m = RandomForestRegressor(2000, min_samples_leaf=15, max_samples=100, max_features=0.5,n_jobs=-1, oob_score=True)\n",
    "    m.fit(df,esol_y)\n",
    "    return m.oob_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_oob(data[pruned_list].values), "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{c: get_oob(data[pruned_list].drop(c,axis=1)) for c in data[pruned_list].columns}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try removing Chi1v and MaxAbsPartialCharge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_fi(rf_feat_importance(m,pruned_list))\n",
    "to_drop = ['Chi1v','MaxAbsPartialCharge', 'Chi4n','Chi4v','Chi3v','BertzCT','FpDensityMorgan1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(24,20))\n",
    "sns.set_context(font_scale=1.5)\n",
    "ax=sns.heatmap(xs_imps.drop(to_drop,axis=1).corr(), cmap='magma', annot=True)\n",
    "plt.savefig('../models/LOGS/features_heatmap.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_columns(xs_imps[to_keep])\n",
    "plt.savefig('../models/LOGS/features_dendrogram.png',dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep = list(xs_imps.drop(to_drop,axis=1).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_oob(data[to_keep]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so our final dataset consists of 9 features. It seems it removed all highly redudant features and only selected the most informative ones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_data = data[data.columns[0:11].tolist() + to_keep.tolist()]\n",
    "pruned_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_data.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Detecting outliers**\n",
    "\n",
    "https://www.ucd.ie/ecomodel/Resources/QQplots_WebVersion.html\n",
    "\n",
    "https://www.dummies.com/programming/big-data/data-science/graphical-tests-of-data-outliers/\n",
    "\n",
    "https://machinelearningmastery.com/how-to-use-statistics-to-identify-outliers-in-data/\n",
    "\n",
    "https://towardsdatascience.com/ways-to-detect-and-remove-the-outliers-404d16608dba\n",
    "\n",
    "https://www.dbs.ifi.lmu.de/Publikationen/Papers/LOF.pdf\n",
    "\n",
    "https://towardsdatascience.com/local-outlier-factor-for-anomaly-detection-cc0c770d2ebe\n",
    "\n",
    "\n",
    "**Normality tests**\n",
    "\n",
    "Machine learning mastery post: https://machinelearningmastery.com/a-gentle-introduction-to-normality-tests-in-python/\n",
    "\n",
    "Shapiro-Wilk test: https://www.itl.nist.gov/div898/handbook/prc/section2/prc213.htm\n",
    "\n",
    "Anderson-Darling test : https://www.itl.nist.gov/div898/handbook/prc/section2/prc21.htm\n",
    "\n",
    "\n",
    "GraphPad entry: https://www.graphpad.com/guides/prism/latest/statistics/stat_choosing_a_normality_test.htm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
