{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c rdkit rdkit Install rdkit before running this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rdkit.Chem import MolFromSmiles, MolToSmiles\n",
    "from fastai.vision.all import *\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import IPython.display\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as tmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Chemception in fastai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi! This is will be the first post from my new blog. I hope you guys enjoy it.\n",
    "\n",
    "I'm doing the Fast.AI course and I decided to try solve some problems from my field of research (Cheminformatics) using the fastai package. In this blog, I will try to follow the chapters from the [Deep Learning for Coders with fastai & Pytorch](https://www.amazon.com.br/gp/product/1492045527/ref=ppx_yo_dt_b_asin_title_o00_s00?ie=UTF8&psc=1). For instance, this notebook was inspired by chapter 2 (the notebook version can be found [here](https://github.com/fastai/fastbook/blob/master/02_production.ipynb))\n",
    "\n",
    "Let's begin!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, what are we going to do?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will try to solve a quantitative structure-activity relationship QSAR problem. What does this mean? Well, QSAR is a major aspect of Cheminformatics. The goal of QSAR is to find useful information in chemical and biological data and use this information for inference on new data. For example, we might want to predict if a molecule is active on a particular biological target. We could start with a dataset of experimentally measured bioactivities (e.g. $IC_{50}$ values, inhibition constants etc) and train a model for bioactivity prediction. This model can be used to predict the bioactivity of other molecules of interest. By using QSAR, BigPharma and research groups can generate new hypothesis much faster and cheaper than testing a bunch of molecules in vitro. \n",
    "\n",
    "Traditionally, machine learning methods such as random forest, support vector machines and gradient boosting dominate the field. That's because these classical methods usually give very good results for a range of datasets and are quite easy to train. Until recently, researchers did not apply deep learning in large scale to bioactivity prediction. When they did, it was usually in the form of fully connected neural with just 2-5 layers. However, the last 5 years saw a BOOM in the number of publications using deep learning in very interesting ways! For example, recurrent neural networks are being applied to generate molecules, convnets are showing SOTA performance on binding affinity and pose prediction and multi-task learning was used successfully to win a Kaggle competition for bioactivity prediction!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most common type of data for QSAR is tabular. Researchers usually calculate many chemical features to describe a collection of molecules. As an example, one of the most common consists in a binary vector indicating the presence/absence of chemical groups in a molecule. We can then use this ***fingerprint*** to train a macihine learning model for bioactivity prediction.\n",
    "\n",
    "In this notebook we will use a different strategy. Instead of calculating a bunch of vectors, we'll convert each molecule to an image and feed that input to a neural network! As Jeremy said in the book: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ```Another point to consider is that although your problem might not look like a computer vision problem, it might be possible with a little imagination to turn it into one. For instance, if what you are trying to classify are sounds, you might try converting the sounds into images of their acoustic waveforms and then training a model on those images.```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try that!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How can we convert molecules to images?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In reality, we are not going to convert molecules to images of molecules. What we actually need is a way to represent molecules the same way as images. That way consists of using arrays. For example, an image can be represented as 3D array of shape $(W, H, C)$, where $W$ is the width, $H$ is the height and $C$ is the number of channels. If we could do that to molecules, then it would be straightforward to use it as input to a model. \n",
    "\n",
    "There are many ways to do that, but we are going to use one that I think is very interesting. In 2017, Garrett B. Goh, Charles Siegel, Abhinav Vishnu, Nathan O. Hodas and Nathan Baker published a preprint showing that machine learning models actually don't need to know much about chemistry or biology to make a prediction! \n",
    "\n",
    "In their original [manuscript](https://arxiv.org/abs/1706.06689), the authors called their model **Chemception** and showed that using very, very simple image-like inputs it was possible to achieve SOTA performance on some public datasets. That's quite an achievement! Until yesterday, the cheminformatics community was using handcrafted features and now it seems we don't even need to tell many things about molecules to train a predictive model!\n",
    "\n",
    "As the author mentioned in the preprint:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> In addition, it should be emphasized that no additional\n",
    "source of chemistry-inspired features or inputs, such as molecular descriptors or fingerprints were\n",
    "used in training the model. This means that Chemception was not explicitly provided with even\n",
    "the most basic chemical concepts like “valency” or “periodicity”."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means that Chemception had to learn A LOT about chemistry from scratch, using only not very informative inputs (to humans, at least)! \n",
    "\n",
    "I really find this amazing!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Just to clarify: I'm not saying the model would be useful in real settings. But it is quite amazing to see a good performance without using elaborate chemical descriptors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chemception model is a convolutional neural network for QSAR tasks. An overview of their method is shown below: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/post1_chemception_input.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Load data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use a dataset of molecules screened against coagulation factor Xa. Our objective is to train a model for bioactivity prediction given only a image-like representation of the molecules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = pd.read_csv('/home/marcossantana/Documentos/GitHub/marcossantanaioc.github.io/_data/fxa_ic50_processed.csv',sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc_id</th>\n",
       "      <th>standard_value</th>\n",
       "      <th>standard_type</th>\n",
       "      <th>standard_relation</th>\n",
       "      <th>pchembl</th>\n",
       "      <th>molregno</th>\n",
       "      <th>canonical_smiles</th>\n",
       "      <th>chembl_id</th>\n",
       "      <th>target_dictionary</th>\n",
       "      <th>target_chembl_id</th>\n",
       "      <th>l1</th>\n",
       "      <th>l2</th>\n",
       "      <th>l3</th>\n",
       "      <th>confidence_score</th>\n",
       "      <th>act</th>\n",
       "      <th>processed_smiles</th>\n",
       "      <th>is_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>47181</td>\n",
       "      <td>1.5</td>\n",
       "      <td>IC50</td>\n",
       "      <td>=</td>\n",
       "      <td>8.82</td>\n",
       "      <td>459679</td>\n",
       "      <td>COc1ccc(NC(=O)c2ccc(C(=N)N(C)C)cc2)c(C(=O)Nc2ccc(Cl)cn2)c1</td>\n",
       "      <td>CHEMBL512351</td>\n",
       "      <td>194</td>\n",
       "      <td>CHEMBL244</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>Protease</td>\n",
       "      <td>Serine protease</td>\n",
       "      <td>8</td>\n",
       "      <td>Active</td>\n",
       "      <td>COc1ccc(NC(=O)c2ccc(C(=N)N(C)C)cc2)c(C(=O)Nc2ccc(Cl)cn2)c1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30088</td>\n",
       "      <td>29000.0</td>\n",
       "      <td>IC50</td>\n",
       "      <td>=</td>\n",
       "      <td>4.54</td>\n",
       "      <td>655811</td>\n",
       "      <td>Cc1ccc(Oc2nc(Oc3cccc(C(=N)N)c3)c(F)c(NC(C)CCc3ccccc3)c2F)c(C(=O)O)c1</td>\n",
       "      <td>CHEMBL193933</td>\n",
       "      <td>194</td>\n",
       "      <td>CHEMBL244</td>\n",
       "      <td>Enzyme</td>\n",
       "      <td>Protease</td>\n",
       "      <td>Serine protease</td>\n",
       "      <td>9</td>\n",
       "      <td>Inactive</td>\n",
       "      <td>Cc1ccc(Oc2nc(Oc3cccc(C(=N)N)c3)c(F)c(NC(C)CCc3ccccc3)c2F)c(C(=O)O)c1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   doc_id  standard_value standard_type standard_relation  pchembl  molregno  \\\n",
       "0   47181             1.5          IC50                 =     8.82    459679   \n",
       "1   30088         29000.0          IC50                 =     4.54    655811   \n",
       "\n",
       "                                                       canonical_smiles  \\\n",
       "0            COc1ccc(NC(=O)c2ccc(C(=N)N(C)C)cc2)c(C(=O)Nc2ccc(Cl)cn2)c1   \n",
       "1  Cc1ccc(Oc2nc(Oc3cccc(C(=N)N)c3)c(F)c(NC(C)CCc3ccccc3)c2F)c(C(=O)O)c1   \n",
       "\n",
       "      chembl_id  target_dictionary target_chembl_id      l1        l2  \\\n",
       "0  CHEMBL512351                194        CHEMBL244  Enzyme  Protease   \n",
       "1  CHEMBL193933                194        CHEMBL244  Enzyme  Protease   \n",
       "\n",
       "                l3  confidence_score       act  \\\n",
       "0  Serine protease                 8    Active   \n",
       "1  Serine protease                 9  Inactive   \n",
       "\n",
       "                                                       processed_smiles  \\\n",
       "0            COc1ccc(NC(=O)c2ccc(C(=N)N(C)C)cc2)c(C(=O)Nc2ccc(Cl)cn2)c1   \n",
       "1  Cc1ccc(Oc2nc(Oc3cccc(C(=N)N)c3)c(F)c(NC(C)CCc3ccccc3)c2F)c(C(=O)O)c1   \n",
       "\n",
       "   is_valid  \n",
       "0     False  \n",
       "1     False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mols.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```chemcepterize_mol``` function below will take care of converting the molecules SMILES strings (a one-line representation of the chemical structure) to the image-like format that we want. \n",
    "\n",
    "Our workflow will go like this: first we define an embedding dimension and a resolution.  You can think of this is a black canvas where the structures will be plotted and each atom will have a resolution consisting of how many pixels will be used to represent it. The dimensions of the canvas will be given by:\n",
    "\n",
    "\n",
    "$$DIM = \\frac{EMBED*2}{RES}$$\n",
    "\n",
    "where $EMBED$ is the embedding size and  $RES$ the resolution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "The next step consists of calculating some basic chemical information from the structure, such as bond order, charges, atomic numbers and the hybridization states. This information will be converted into a matrix of shape $(P, DIM, DIM)$, where $P$ is the number of properties or channels in the image (in this case we will use 3) and $DIM$ is the dimension of the canvas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chemcepterize_mol(mol, embed=20.0, res=0.5):\n",
    "    dims = int(embed*2/res)\n",
    "    #print(dims)\n",
    "   \n",
    "    #print(mol)\n",
    "    #print(\",,,,,,,,,,,,,,,,,,,,,,\")\n",
    "    cmol = Chem.Mol(mol.ToBinary())\n",
    "    #print(cmol)\n",
    "    #print(\",,,,,,,,,,,,,,,,,,,,,,\")\n",
    "    cmol.ComputeGasteigerCharges()\n",
    "    AllChem.Compute2DCoords(cmol)\n",
    "    coords = cmol.GetConformer(0).GetPositions()\n",
    "    #print(coords)\n",
    "    #print(\",,,,,,,,,,,,,,,,,,,,,,\")\n",
    "    vect = np.zeros((dims+2,dims+2,4)) # I added 2 pixels on to height and width because this function sometimes does not work if the molecule is too big.\n",
    "    \n",
    "    #Bonds first\n",
    "    for i,bond in enumerate(mol.GetBonds()):\n",
    "        bondorder = bond.GetBondTypeAsDouble()\n",
    "        bidx = bond.GetBeginAtomIdx()\n",
    "        eidx = bond.GetEndAtomIdx()\n",
    "        bcoords = coords[bidx]\n",
    "        ecoords = coords[eidx]\n",
    "        frac = np.linspace(0,1,int(1/res*2)) #\n",
    "        for f in frac:\n",
    "            c = (f*bcoords + (1-f)*ecoords)\n",
    "            idx = int(round((c[0] + embed)/res))\n",
    "            idy = int(round((c[1]+ embed)/res))\n",
    "            #Save in the vector first channel\n",
    "            vect[ idx , idy ,0] = bondorder\n",
    "            \n",
    "    #Atom Layers\n",
    "    for i,atom in enumerate(cmol.GetAtoms()):\n",
    "            idx = int(round((coords[i][0] + embed)/res))\n",
    "            idy = int(round((coords[i][1]+ embed)/res))\n",
    "            #Atomic number\n",
    "            vect[ idx , idy, 1] = atom.GetAtomicNum()\n",
    "            \n",
    "            #Hybridization\n",
    "            hyptype = atom.GetHybridization().real\n",
    "            vect[ idx , idy, 2] = hyptype\n",
    "            \n",
    "            #Gasteiger Charges\n",
    "            charge = atom.GetProp(\"_GasteigerCharge\")\n",
    "            vect[ idx , idy, 3] = charge\n",
    "\n",
    "            \n",
    "    return Tensor(vect[:, :, :3].T) # We will omit the last dimension just to fit our fastai models. But you can also adapt the architeture to deal with 4 or more channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to calculate the final dimensions? \n",
    "#an embedding of 32 will give a 128 x 128 canvas. We can use this correlation to generate images of any size. (224 * 32)/128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will create a column called ```mol``` that maps our molecular structures to ```rdkit.Chem.rdchem.Mol``` objects. This is essential because we are going to use Rdkit to calculate everything and ```rdkit.Chem.rdchem.Mol```  has a bunch of nice functionalities to work with molecular graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rdkit.Chem.rdchem.Mol"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mol= MolFromSmiles('c1ccccc1') # A rdkit.Chem.rdchem.Mol object representing benzene\n",
    "type(mol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols['mol'] = mols['processed_smiles'].apply(MolFromSmiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to vectorize our molecules and transform them to image-like matrices.But first, let's test our function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(mol, embed, res):\n",
    "    return chemcepterize_mol(mol, embed=embed, res=res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = vectorize(mols[\"mol\"][0],embed=56, res=0.5).T.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now let's see what that does!\n",
    "\n",
    "As you can see, the image is mostly black space and the molecule is just a tiny, tiny part of it (shown in red). The black spaces have no chemical information at all! That's why the authors said Chemception had to learn everything from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(226, 226, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2df28dcc10>"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(print(v.shape))\n",
    "plt.imshow(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make bigger molecules by reducing the embedding size. ***But beware that will also reduce the total image size***."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "larger_img = vectorize(mols[\"mol\"][0],embed=16, res=0.5).T.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66, 66, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2df28a36d0>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.show(print((larger_img.shape)))\n",
    "plt.imshow(larger_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mols[\"molimage\"] = mols[\"mol\"].apply(partial(vectorize, embed=16, res=0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f2df2a52790>"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(mols[\"molimage\"][0].T.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know how to convert the molecules to the desired format, we are ready to train a model using fastai! In order to do that, we need to define **three things**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) **How to split data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's define how to split our data into training and validation sets. Luckly, our dataset comes with a column called \"is_valid\" showing which molecules should be used for validation and training. Therefore, we will use the ```ColSplitter``` class from fastai to get the indeces. We could also do a random split here or any kind at all. Fastai is very flexible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((#1703) [0,1,2,3,4,5,6,7,8,9...],\n",
       " (#426) [1703,1704,1705,1706,1707,1708,1709,1710,1711,1712...])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits = ColSplitter('is_valid')(mols)\n",
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Define how to get the items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to tell fastai how to get the items that we'll feed to our model. In this case, we will use the images we created and stored in the \"molimage\" column of our dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_tfms = ColReader('molimage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Define the targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to tell fastai where are our targets. In this case, our targets are in the column \"act\", showing the bioactivity of each molecule. We will also tell fastai to treat the values of this column as categories, which will be used to train a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tfms = [ColReader('act'),Categorize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The fastai book uses the DataBlock functionality to create the dataloaders at Chapter 2 and Jeremy says that we actually need **four things** \n",
    "\n",
    "\n",
    "> 1. What kind of data to work with;\n",
    "> 2. How to get the items;\n",
    "> 3. How to label these items;\n",
    "> 4. How to create a validation set.\n",
    "\n",
    "\n",
    "> But since we are using a custom data type, we'll skip the step defining the kind of data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "mol_dataset = Datasets(mols,[x_tfms,y_tfms], splits=splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = mol_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 66, 66]), TensorCategory(0))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "        [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems everything is in order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Create dataloaders**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mol_dataset.dataloaders(batch_size=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect one batch to see if everything is already:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "         [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       " \n",
       "          [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           ...,\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "           [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0'),\n",
       " TensorCategory([0, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'))"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alright! Let's train this beast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth\" to /home/marcossantana/.cache/torch/hub/checkpoints/inception_v3_google-1a9a5a14.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0baa296089b744a2a7ede667c64067d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=108857766.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "inception = tmodels.inception_v3(pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [Recall(pos_label=1),Recall(pos_label = 0), Precision(pos_label = 0), MatthewsCorrCoef()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "forward() got an unexpected keyword argument 'pretrained'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-177-cd191c1d518b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlearn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_learner\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai/vision/learner.py\u001b[0m in \u001b[0;36mcnn_learner\u001b[0;34m(dls, arch, normalize, n_out, pretrained, config, loss_func, opt_func, lr, splitter, cbs, metrics, path, model_dir, wd, wd_bn_bias, train_bn, moms, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mn_out\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mn_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_c\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0msplitter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplitter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'split'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai/vision/learner.py\u001b[0m in \u001b[0;36mcreate_cnn_model\u001b[0;34m(arch, n_out, pretrained, cut, n_in, init, custom_head, concat_pool, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m\"Create custom convnet architecture\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_meta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_default_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m     \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mifnone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcut\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'cut'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcustom_head\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mnf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_features_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconcat_pool\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/fastai/vision/learner.py\u001b[0m in \u001b[0;36mcreate_body\u001b[0;34m(arch, n_in, pretrained, cut)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcreate_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0march\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcut\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;34m\"Cut off the body of a typically pretrained `arch` as determined by `cut`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0march\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m     \u001b[0m_update_first_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0;31m#cut = ifnone(cut, cnn_config(arch)['cut'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: forward() got an unexpected keyword argument 'pretrained'"
     ]
    }
   ],
   "source": [
    "learn = cnn_learner(dls, inception, metrics=metrics,ps=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.014963</td>\n",
       "      <td>0.976047</td>\n",
       "      <td>0.389610</td>\n",
       "      <td>0.786765</td>\n",
       "      <td>0.694805</td>\n",
       "      <td>0.189350</td>\n",
       "      <td>00:13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.743405</td>\n",
       "      <td>0.723393</td>\n",
       "      <td>0.474026</td>\n",
       "      <td>0.856618</td>\n",
       "      <td>0.742038</td>\n",
       "      <td>0.360854</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.708820</td>\n",
       "      <td>0.672125</td>\n",
       "      <td>0.422078</td>\n",
       "      <td>0.841912</td>\n",
       "      <td>0.720126</td>\n",
       "      <td>0.291545</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.672087</td>\n",
       "      <td>0.618258</td>\n",
       "      <td>0.370130</td>\n",
       "      <td>0.889706</td>\n",
       "      <td>0.713864</td>\n",
       "      <td>0.309659</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.570753</td>\n",
       "      <td>0.616032</td>\n",
       "      <td>0.435065</td>\n",
       "      <td>0.852941</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.319050</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.525761</td>\n",
       "      <td>0.641829</td>\n",
       "      <td>0.422078</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>0.715655</td>\n",
       "      <td>0.267285</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.405778</td>\n",
       "      <td>0.618050</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.841912</td>\n",
       "      <td>0.771044</td>\n",
       "      <td>0.418615</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.308775</td>\n",
       "      <td>0.631137</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.797794</td>\n",
       "      <td>0.794872</td>\n",
       "      <td>0.434776</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.247828</td>\n",
       "      <td>0.546324</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.856618</td>\n",
       "      <td>0.779264</td>\n",
       "      <td>0.449571</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.211691</td>\n",
       "      <td>0.624223</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.803571</td>\n",
       "      <td>0.475823</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.172085</td>\n",
       "      <td>0.628644</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.827206</td>\n",
       "      <td>0.800712</td>\n",
       "      <td>0.470027</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems everything went pretty well! In addition, the Matthew's correlation coefficient is quite decent (~0.47)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The performance is pretty decent, if without any kind of data augmentation and hyperparameter optimization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try with a little bit of data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the original paper, the authors used random rotations of the images. Why is that? Well, since most of the image is empty space, if we distort it even a little bit, by cropping or squishing, it might completly change the molecule represented. Rotating the image is a solution to the data augmentation problem because in this particular case it won't change the meaning of our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = mol_dataset.dataloaders(batch_size=8,after_batch=Rotate(max_deg=180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = dls.one_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "          [0., 0., 0.,  ..., 0., 0., 0.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = cnn_learner(dls, resnet18, metrics=metrics,ps=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.143972</td>\n",
       "      <td>0.989585</td>\n",
       "      <td>0.435065</td>\n",
       "      <td>0.658088</td>\n",
       "      <td>0.672932</td>\n",
       "      <td>0.092415</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.734130</td>\n",
       "      <td>0.769404</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.819853</td>\n",
       "      <td>0.681957</td>\n",
       "      <td>0.164402</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.662358</td>\n",
       "      <td>0.730938</td>\n",
       "      <td>0.324675</td>\n",
       "      <td>0.808824</td>\n",
       "      <td>0.679012</td>\n",
       "      <td>0.150297</td>\n",
       "      <td>00:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.683944</td>\n",
       "      <td>0.701908</td>\n",
       "      <td>0.253247</td>\n",
       "      <td>0.878676</td>\n",
       "      <td>0.675141</td>\n",
       "      <td>0.169121</td>\n",
       "      <td>00:17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.567569</td>\n",
       "      <td>0.596359</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.783088</td>\n",
       "      <td>0.785978</td>\n",
       "      <td>0.405898</td>\n",
       "      <td>00:16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.494952</td>\n",
       "      <td>0.618644</td>\n",
       "      <td>0.551948</td>\n",
       "      <td>0.794118</td>\n",
       "      <td>0.757895</td>\n",
       "      <td>0.353323</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.465884</td>\n",
       "      <td>0.573632</td>\n",
       "      <td>0.558442</td>\n",
       "      <td>0.805147</td>\n",
       "      <td>0.763066</td>\n",
       "      <td>0.372569</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.360215</td>\n",
       "      <td>0.624135</td>\n",
       "      <td>0.538961</td>\n",
       "      <td>0.849265</td>\n",
       "      <td>0.764901</td>\n",
       "      <td>0.410596</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.289461</td>\n",
       "      <td>0.613367</td>\n",
       "      <td>0.675325</td>\n",
       "      <td>0.797794</td>\n",
       "      <td>0.812734</td>\n",
       "      <td>0.469960</td>\n",
       "      <td>00:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.202756</td>\n",
       "      <td>0.662318</td>\n",
       "      <td>0.662338</td>\n",
       "      <td>0.812500</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.475514</td>\n",
       "      <td>00:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.175540</td>\n",
       "      <td>0.674199</td>\n",
       "      <td>0.623377</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>0.798611</td>\n",
       "      <td>0.481448</td>\n",
       "      <td>00:12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.fine_tune(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp = ClassificationInterpretation.from_learner(learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "interp.plot_confusion_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a little bit better now :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we trained the model, we can export it and use it for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn_inf = load_learner('export.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('Inactive', tensor(1), tensor([0.0163, 0.9837]))"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn_inf.predict(mols['molimage'][2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fin"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
